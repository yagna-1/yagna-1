<!--
  GitHub Profile README (repo must be named exactly: yagna-1)
-->

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&height=170&color=0:00ff41,100:00f0ff&section=header&text=Yagna%20Siva%20Sai%20Kumar&fontSize=42&fontAlignY=35&desc=AI%2FML%20Engineer%20%E2%80%A2%20LLM%20Evaluation%20%E2%80%A2%20RAG%20%E2%80%A2%20MLOps&descAlignY=60&fontColor=0b0f0f" />

<p>
  <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&size=20&pause=900&color=00FF41&center=true&vCenter=true&width=900&lines=AI%2FML+Engineer+%E2%80%A2+End-to-end+ML+systems+%E2%80%A2+LLM+evaluation;Benchmarks+%26+distributed+inference+pipelines+%28AWS%29;RAG+%28semantic+%2B+BM25%29+%E2%80%A2+failure-case+analysis+%E2%80%A2+latency+metrics;On-device+agent+fine-tuning+%E2%80%A2+quantization+%E2%80%A2+agentic+workflows" alt="Typing SVG" />
</p>

<p>
  <a href="https://yagna-1.vercell.app"><img alt="Portfolio" src="https://img.shields.io/badge/Portfolio-00f0ff?style=for-the-badge&logo=vercel&logoColor=000000" /></a>
  <a href="mailto:yagnasivasaikumar@gmail.com"><img alt="Email" src="https://img.shields.io/badge/Email-00ff41?style=for-the-badge&logo=gmail&logoColor=000000" /></a>
  <a href="https://linkedin.com/in/yagna-siva-sai-kumar-984881201/"><img alt="LinkedIn" src="https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=ffffff" /></a>
  <a href="https://arxiv.org/abs/2502.12115"><img alt="arXiv" src="https://img.shields.io/badge/arXiv-2502.12115-b31b1b?style=for-the-badge&logo=arxiv&logoColor=ffffff" /></a>
</p>

<p>
  <img alt="Python" src="https://img.shields.io/badge/Python-111111?style=flat-square&logo=python&logoColor=00ff41" />
  <img alt="Go" src="https://img.shields.io/badge/Go-111111?style=flat-square&logo=go&logoColor=00ADD8" />
  <img alt="Ruby" src="https://img.shields.io/badge/Ruby-111111?style=flat-square&logo=ruby&logoColor=CC342D" />
  <img alt="RAG" src="https://img.shields.io/badge/RAG-111111?style=flat-square&logo=openai&logoColor=00f0ff" />
  <img alt="LLM Evaluation" src="https://img.shields.io/badge/LLM_Eval-111111?style=flat-square&logo=githubactions&logoColor=ffffff" />
  <img alt="Prompt Engineering" src="https://img.shields.io/badge/Prompt_Engineering-111111?style=flat-square&logo=fastapi&logoColor=00f0ff" />
  <img alt="AWS" src="https://img.shields.io/badge/AWS-111111?style=flat-square&logo=amazonaws&logoColor=ff9900" />
  <img alt="Docker" src="https://img.shields.io/badge/Docker-111111?style=flat-square&logo=docker&logoColor=2496ED" />
  <img alt="Postgres" src="https://img.shields.io/badge/Postgres-111111?style=flat-square&logo=postgresql&logoColor=4169E1" />
</p>

</div>

---

## About

AI/ML Engineer with hands-on experience building **end-to-end ML systems**—from data preprocessing and feature engineering to training, evaluation, and cloud deployment. Strong background in **LLM evaluation**, **RAG pipelines**, classical ML experimentation, and **scalable inference on AWS**.

- **Current focus**: hybrid retrieval (semantic + BM25), tool-using agents, eval harnesses, cost/latency optimization  
- **Location**: Vijayawada, India (remote-friendly)  

---

## What I build

- **Benchmarks & evaluation**: datasets, scoring, regression tests, quality dashboards
- **RAG systems**: hybrid retrieval, citations, traceability, eval-driven iteration
- **Agentic workflows**: tool use, orchestration, reliability + monitoring
- **Inference pipelines**: distributed runs, batching, caching, and throughput optimization (AWS)

---

## Highlights

- Contributed to the **OpenAI SWE‑Lancer benchmark** (arXiv `2502.12115`) evaluating LLMs on **1,400+ real-world engineering tasks** (Expensify OSS)
- Built a **distributed inference pipeline** to run **1000+ tasks in parallel** on AWS
- Architected a **hybrid RAG pipeline** (semantic + BM25) with **ChromaDB/FAISS**, improving retrieval accuracy by **~25%**
- Designed evaluation experiments using **precision/recall, latency, and failure-case analysis** to compare retrieval approaches and guide iteration
- Improved response fidelity via **prompt engineering** (few-shot + tuning), reducing hallucinations by **~20%**
- Built reusable **data preprocessing + validation pipelines** to keep training/evaluation consistent across model versions

---

## Featured projects

> A few repos I’m actively working on / proud of.

<div align="center">

<a href="https://github.com/yagna-1/Vectorless-RAG">
  <img src="https://opengraph.githubassets.com/1/yagna-1/Vectorless-RAG" alt="Vectorless-RAG" />
</a>
<a href="https://github.com/yagna-1/AgentScopeLocal">
  <img src="https://opengraph.githubassets.com/1/yagna-1/AgentScopeLocal" alt="AgentScopeLocal" />
</a>

<a href="https://github.com/yagna-1/Memory-KV-Cache">
  <img src="https://opengraph.githubassets.com/1/yagna-1/Memory-KV-Cache" alt="Memory-KV-Cache" />
</a>

</div>

### Quick links

| Project | What it is | Stack | Links |
|---|---|---|---|
| **Vectorless-RAG** | “PageIndex-style” RAG with **page-level citations** (no vectors / no chunking) | Next.js, Postgres, Groq | Repo: `https://github.com/yagna-1/Vectorless-RAG` • Demo: `https://vectorless-rag.vercel.app` |
| **AgentScopeLocal** | Privacy-first **LLM observability** + beautiful terminal traces (local-first) | Python, OpenTelemetry, SQLite, FastAPI | Repo: `https://github.com/yagna-1/AgentScopeLocal` |
| **Memory-KV-Cache** | Memory-aware LLM manager for macOS with **KV-cache inspection** tools | Rust | Repo: `https://github.com/yagna-1/Memory-KV-Cache` |

---

## Experience

### Turing — Python AI/ML Developer (Mar 2024 – Present)

- Engineered the evaluation pipeline for the **OpenAI SWE‑Lancer benchmark** (`https://arxiv.org/abs/2502.12115`), benchmarking LLMs on **1,400+** real-world engineering tasks
- Collaborated with data scientists + PMs to align model work with business goals, accelerating iteration via a **distributed 1000+ task parallel inference pipeline**
- Architected a hybrid RAG pipeline on AWS (EC2/S3) integrating **semantic search + BM25** with **ChromaDB/FAISS**, improving retrieval accuracy by **~25%**
- Designed evaluation experiments using **precision/recall, latency, and failure-case analysis** to compare baselines vs hybrid retrieval
- Optimized prompt strategies to reduce hallucinations by **~20%**
- Built reusable preprocessing + validation pipelines to support repeatable experimentation across model versions

### Genpact — Data Engineering Intern (Jul 2023 – Dec 2023)

- Performed dataset preparation, feature extraction, and evaluation for NLP/RAG models; validated improvements before production integration on **Microsoft Azure**
- Built a web scraping platform using **React + Flask + PostgreSQL + LLMs/LangChain**
- Integrated an AI chatbot to improve retrieval efficiency and UX

---

## Selected projects

- **FunctionGemma On‑Device Agent (Dec 2025)**  
  Fine-tuned Google’s **FunctionGemma‑270M** to execute structured function calls locally on Android; optimized for edge deployment using quantization for high‑performance inference with minimal memory footprint.

- **Telugu OCR Fine-tuning (Sep 2025)**  
  Fine-tuned **DeepSeek‑OCR VLM** on a Telugu dataset using **LoRA (rank‑32)** + **4‑bit quantization**, achieving **~10% CER** (≈30% improvement from baseline).
  Leveraged **Unsloth** and QLoRA to speed up fine-tuning by **~2×** on a single GPU.

- **NotebookLM — Multi‑Agent RAG System (Mar 2025)**  
  Developed an autonomous “AI crew” (CrewAI) to process multi‑modal inputs (**PDF / audio / web**) and generate an AI podcast using **Kokoro‑82M TTS**.

- **Self‑Hosted Code Analysis Tool (Dec 2024)**  
  Local **LLaMA‑3B** inference with **4‑bit quantization** + RAG (ChromaDB) and **hybrid retrieval (BM25 + embeddings)** with contextual web search integration.

---

## Tech stack

<div align="center">
  <img src="https://skillicons.dev/icons?i=python,go,ruby,pytorch,tensorflow,aws,docker,kubernetes,postgres,react,ts,nodejs,linux&perline=7" />
</div>

**AI/ML**: RAG, semantic search, prompt engineering, evaluation, quantization  
**Vector / data**: Milvus, ChromaDB, FAISS, PostgreSQL  
**Cloud/MLOps**: AWS, Docker, Kubernetes, CI/CD  
**Web**: React, TypeScript, Node.js, FastAPI  

---

## Skills

- **Languages**: Python, Go, Ruby, SQL, TypeScript, JavaScript  
- **AI/ML frameworks**: PyTorch, TensorFlow, Hugging Face, LangChain, CrewAI, Scikit‑learn  
- **Techniques**: RAG, LLM fine-tuning (LoRA/QLoRA), quantization, agentic workflows, semantic search  
- **Data / vector stores**: Milvus, ChromaDB, FAISS, PostgreSQL, MySQL, pandas, NumPy  
- **Cloud / MLOps**: AWS, Docker, Kubernetes, Git, FastAPI, CI/CD  

---

## Education

- **B.Tech (ECE)** — NIT Jaipur (2020 – 2024)

---

## Principles

- **Measure, don’t guess**: retrieval metrics, eval harnesses, regression tests  
- **Simple + scalable**: clear interfaces, debuggable pipelines, good defaults  
- **Reliability**: guardrails, observability, failure analysis, iterative improvement  

---

## Let’s connect

- **Portfolio**: `https://yagna-1.vercell.app`
- **Email**: `yagnasivasaikumar@gmail.com`
- **LinkedIn**: `https://linkedin.com/in/yagna-siva-sai-kumar-984881201/`

---

<details>
<summary><b>Forks / references (upstream inspiration)</b></summary>
<br />

- `https://github.com/yagna-1/hive` (fork)
- `https://github.com/yagna-1/awesome-claude-skills` (fork)

</details>

<details>
<summary><b>Optional: GitHub stats</b></summary>
<br />
<p align="center">
  <img alt="Followers" src="https://img.shields.io/github/followers/yagna-1?style=for-the-badge&label=Followers&color=00ff41&labelColor=111111" />
  <img alt="Vectorless-RAG stars" src="https://img.shields.io/github/stars/yagna-1/Vectorless-RAG?style=for-the-badge&label=Vectorless-RAG%20Stars&color=00f0ff&labelColor=111111" />
  <img alt="AgentScopeLocal stars" src="https://img.shields.io/github/stars/yagna-1/AgentScopeLocal?style=for-the-badge&label=AgentScopeLocal%20Stars&color=00f0ff&labelColor=111111" />
  <img alt="Memory-KV-Cache stars" src="https://img.shields.io/github/stars/yagna-1/Memory-KV-Cache?style=for-the-badge&label=Memory-KV-Cache%20Stars&color=00f0ff&labelColor=111111" />
</p>
</details>

